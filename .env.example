# =============================================================================
# AI Assistant — Environment Configuration
# Copy this file to .env and fill in your values.
# =============================================================================

# -----------------------------------------------------------------------------
# Required
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=sk-ant-...

# -----------------------------------------------------------------------------
# Core
# -----------------------------------------------------------------------------
ASSISTANT_MODEL=claude-sonnet-4-20250514
ASSISTANT_MAX_TOKENS=8192
ASSISTANT_DATA_DIR=./data
ASSISTANT_LOG_LEVEL=INFO         # DEBUG | INFO | WARNING | ERROR

# Server (for `assistant serve`)
ASSISTANT_HOST=127.0.0.1
ASSISTANT_PORT=8000

# Session
ASSISTANT_MAX_CONTEXT_MESSAGES=50
ASSISTANT_AUTO_APPROVE_READS=true   # auto-approve read-only tool calls

# Default provider — which LLM to use (claude | openai | gemini | ollama)
ASSISTANT_DEFAULT_PROVIDER=claude

# -----------------------------------------------------------------------------
# OpenAI
# -----------------------------------------------------------------------------
OPENAI_API_KEY=sk-...
ASSISTANT_OPENAI_ENABLED=false
ASSISTANT_OPENAI_MODEL=gpt-4o

# -----------------------------------------------------------------------------
# Google Gemini — uses OpenAI-compatible endpoint
# -----------------------------------------------------------------------------
GEMINI_API_KEY=
ASSISTANT_GEMINI_ENABLED=false
ASSISTANT_GEMINI_MODEL=gemini-2.0-flash

# -----------------------------------------------------------------------------
# Ollama — local LLM routing
# Simple/short requests are routed to the local model to save API costs.
# -----------------------------------------------------------------------------
ASSISTANT_OLLAMA_ENABLED=false
ASSISTANT_OLLAMA_BASE_URL=http://host.docker.internal:11434
ASSISTANT_OLLAMA_MODEL=llama3.2
ASSISTANT_LOCAL_MODEL_THRESHOLD_TOKENS=1000   # requests under this go to Ollama

# -----------------------------------------------------------------------------
# Web Search — SearXNG integration
# Self-host SearXNG: https://docs.searxng.org/
# -----------------------------------------------------------------------------
ASSISTANT_WEB_SEARCH_ENABLED=false
ASSISTANT_SEARXNG_URL=http://searxng:8080

# -----------------------------------------------------------------------------
# Vector Search — semantic similarity over conversation history
# Requires Ollama to be running with an embedding model available.
# -----------------------------------------------------------------------------
ASSISTANT_VECTOR_SEARCH_ENABLED=false
ASSISTANT_EMBEDDING_MODEL=nomic-embed-text

# -----------------------------------------------------------------------------
# Media
# -----------------------------------------------------------------------------
ASSISTANT_MAX_MEDIA_SIZE_MB=10

# -----------------------------------------------------------------------------
# Telegram bot
# Create a bot via @BotFather and paste the token below.
# TELEGRAM_ALLOWED_USER_IDS is a comma-separated list of numeric user IDs.
# -----------------------------------------------------------------------------
ASSISTANT_TELEGRAM_ENABLED=false
TELEGRAM_BOT_TOKEN=
ASSISTANT_TELEGRAM_ALLOWED_USER_IDS=   # e.g. 123456789,987654321
ASSISTANT_TELEGRAM_WEBHOOK_URL=        # leave blank to use long-polling

# -----------------------------------------------------------------------------
# WhatsApp bot — neonize linked-device pairing (scan QR on first run)
# WHATSAPP_ALLOWED_NUMBERS is a comma-separated list of E.164 numbers.
# -----------------------------------------------------------------------------
ASSISTANT_WHATSAPP_ENABLED=false
ASSISTANT_WHATSAPP_ALLOWED_NUMBERS=    # e.g. +15551234567,+442071234567
ASSISTANT_WHATSAPP_SESSION_NAME=assistant

# -----------------------------------------------------------------------------
# Scheduler — APScheduler-based automations
# -----------------------------------------------------------------------------
ASSISTANT_SCHEDULER_ENABLED=false
ASSISTANT_SCHEDULER_TIMEZONE=UTC       # e.g. America/New_York, Europe/London

# -----------------------------------------------------------------------------
# Watchdog — file-system monitoring
# WATCHDOG_PATHS is a comma-separated list of paths to watch.
# -----------------------------------------------------------------------------
ASSISTANT_WATCHDOG_ENABLED=false
ASSISTANT_WATCHDOG_PATHS=              # e.g. /home/user/docs,/tmp/incoming
ASSISTANT_WATCHDOG_DEBOUNCE_SECONDS=2.0
ASSISTANT_WATCHDOG_ANALYZE=false       # auto-analyze changed files with LLM

# -----------------------------------------------------------------------------
# Webhooks — inbound HTTP triggers mapped to workflows
# Sign payloads with the secret to pass HMAC-SHA256 validation.
# -----------------------------------------------------------------------------
ASSISTANT_WEBHOOK_ENABLED=false
ASSISTANT_WEBHOOK_SECRET=              # generate with: openssl rand -hex 32

# -----------------------------------------------------------------------------
# Do-Not-Disturb — queue non-urgent notifications during quiet hours
# Times are in 24-hour HH:MM format, interpreted in SCHEDULER_TIMEZONE.
# -----------------------------------------------------------------------------
ASSISTANT_DND_ENABLED=false
ASSISTANT_DND_START=23:00
ASSISTANT_DND_END=07:00
ASSISTANT_DND_ALLOW_URGENT=true        # urgent messages always get through
